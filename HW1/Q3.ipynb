{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ac3f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Pkg\n",
    "Pkg.activate(@__DIR__)\n",
    "Pkg.instantiate()\n",
    "using LinearAlgebra, Plots\n",
    "import ForwardDiff as FD\n",
    "using Printf\n",
    "using JLD2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7142245b",
   "metadata": {},
   "source": [
    "# Q2 (30 pts): Augmented Lagrangian Quadratic Program Solver\n",
    "\n",
    "## Part (A): QP Solver (10 pts)\n",
    "Here we are going to use the augmented lagrangian method described [here in a video](https://www.youtube.com/watch?v=0x0JD5uO_ZQ), with [the corresponding pdf here](https://github.com/Optimal-Control-16-745/lecture-notebooks-2022/blob/main/misc/AL_tutorial.pdf) to solve the following problem:\n",
    "\n",
    "$$\\begin{align}\n",
    "\\min_x \\quad & \\frac{1}{2}x^TQx + q^Tx \\\\ \n",
    "\\mbox{s.t.}\\quad &  Ax -b = 0 \\\\ \n",
    "&  Gx - h \\leq 0 \n",
    "\\end{align}$$\n",
    "where the cost function is described by $Q \\in \\mathbb{R}^{n \\times n}$, $q \\in \\mathbb{R}^n$, an equality constraint is described by $A \\in \\mathbb{R}^{m \\times n}$ and $b \\in \\mathbb{R}^m$, and an inequality constraint is described by $G \\in \\mathbb{R}^{p \\times n}$ and $h \\in \\mathbb{R}^p$.\n",
    "\n",
    "\n",
    "By introducing a dual variable $\\lambda \\in \\mathbb{R}^m$ for the equality constraint, and $\\mu \\in \\mathbb{R}^p$ for the inequality constraint, we have the following KKT conditions for optimality:\n",
    "\n",
    "$$\\begin{align}\n",
    "Qx + q + A^T\\lambda + G^T \\mu &= 0 \\quad \\quad \\text{stationarity}\\\\ \n",
    "Ax-b&= 0 \\quad \\quad \\text{primal feasibility} \\\\ \n",
    "Gx-h&\\leq 0 \\quad \\quad \\text{primal feasibility} \\\\ \n",
    "\\mu &\\geq 0 \\quad \\quad \\text{dual feasibility} \\\\ \n",
    "\\mu \\circ (Gx - h) &= 0 \\quad \\quad \\text{complementarity}\n",
    "  \\end{align}$$\n",
    "  where $\\circ$ is element-wise multiplication.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a03604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: read below\n",
    "# NOTE: DO NOT USE A WHILE LOOP ANYWHERE\n",
    "\"\"\"\n",
    "The data for the QP is stored in `qp` the following way:\n",
    "    @load joinpath(@__DIR__, \"qp_data.jld2\") qp \n",
    "\n",
    "which is a NamedTuple, where\n",
    "    Q, q, A, b, G, h = qp.Q, qp.q, qp.A, qp.b, qp.G, qp.h\n",
    "\n",
    "contains all of the problem data you will need for the QP.\n",
    "\n",
    "Your job is to make the following function \n",
    "    \n",
    "    x, λ, μ = solve_qp(qp; verbose = true, max_iters = 100, tol = 1e-8)\n",
    "\n",
    "You can use (or not use) any of the additional functions:\n",
    "You can use (or not use) any of the additional functions:\n",
    "You can use (or not use) any of the additional functions:\n",
    "You can use (or not use) any of the additional functions:\n",
    "\n",
    "as long as solve_qp works. \n",
    "\"\"\"\n",
    "function cost(qp::NamedTuple, x::Vector)::Real\n",
    "    0.5*x'*qp.Q*x + dot(qp.q,x)\n",
    "end\n",
    "function c_eq(qp::NamedTuple, x::Vector)::Vector\n",
    "    qp.A*x - qp.b \n",
    "end\n",
    "function h_ineq(qp::NamedTuple, x::Vector)::Vector\n",
    "    qp.G*x - qp.h\n",
    "end\n",
    "\n",
    "function mask_matrix(qp::NamedTuple, x::Vector, μ::Vector, ρ::Real)::Matrix\n",
    "    error(\"not implemented\")\n",
    "end\n",
    "function augmented_lagrangian(qp::NamedTuple, x::Vector, λ::Vector, μ::Vector, ρ::Real)::Real\n",
    "    error(\"not implemented\")\n",
    "end\n",
    "function logging(qp::NamedTuple, main_iter::Int, AL_gradient::Vector, x::Vector, λ::Vector, μ::Vector, ρ::Real)\n",
    "    # TODO: stationarity norm\n",
    "    stationarity_norm = 0.0 # fill this in \n",
    "    @printf(\"%3d  % 7.2e  % 7.2e  % 7.2e  % 7.2e  % 7.2e  %5.0e\\n\",\n",
    "          main_iter, stationarity_norm, norm(AL_gradient), maximum(h_ineq(qp,x)),\n",
    "          norm(c_eq(qp,x),Inf), abs(dot(μ,h_ineq(qp,x))), ρ)\n",
    "end\n",
    "function solve_qp(qp; verbose = true, max_iters = 100, tol = 1e-8)\n",
    "    x = zeros(length(qp.q))\n",
    "    λ = zeros(length(qp.b))\n",
    "    μ = zeros(length(qp.h))\n",
    "    \n",
    "    if verbose\n",
    "        @printf \"iter   |∇Lₓ|      |∇ALₓ|     max(h)     |c|        compl     ρ\\n\"\n",
    "        @printf \"----------------------------------------------------------------\\n\"\n",
    "    end\n",
    "    \n",
    "    # TODO:\n",
    "    for main_iter = 1:max_iters \n",
    "        if verbose\n",
    "            logging(qp, main_iter, zeros(1), x, λ, μ, 0.0)\n",
    "        end\n",
    "        \n",
    "        # NOTE: when you do your dual update for μ, you should compute\n",
    "        # your element-wise maximum with `max.(a,b)`, not `max(a,b)`\n",
    "        \n",
    "        # TODO: convergence criteria based on tol \n",
    "        if true \n",
    "            return x, λ, μ\n",
    "        end\n",
    "    end\n",
    "    error(\"qp solver did not converge\")\n",
    "end\n",
    "let \n",
    "    # example solving qp \n",
    "    @load joinpath(@__DIR__, \"qp_data.jld2\") qp \n",
    "    x, λ, μ = solve_qp(qp; verbose = true, tol = 1e-8)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a78f0be",
   "metadata": {},
   "source": [
    "### QP Solver test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48825c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 points \n",
    "using Test \n",
    "@testset \"qp solver\" begin \n",
    "    @load joinpath(@__DIR__, \"qp_data.jld2\") qp \n",
    "    x, λ, μ = solve_qp(qp; verbose = true, max_iters = 100, tol = 1e-6)\n",
    "    \n",
    "    @load joinpath(@__DIR__, \"qp_solutions.jld2\") qp_solutions\n",
    "    @test norm(x - qp_solutions.x,Inf)<1e-3;\n",
    "    @test norm(λ - qp_solutions.λ,Inf)<1e-3;\n",
    "    @test norm(μ - qp_solutions.μ,Inf)<1e-3;\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d469b3",
   "metadata": {},
   "source": [
    "# Simulating a Falling Brick with QPs\n",
    "In this question we'll be simulating a brick falling and sliding on ice in 2D. You will show that this problem can be formulated as a QP, which you will solve using an Augmented Lagrangian method.\n",
    "\n",
    "## The Dynamics\n",
    "The dynamics of the brick can be written in continuous time as\n",
    "$$ M \\dot{v}  + M g = J^T \\mu \\\\ \\text{ where } M = mI_{2\\times 2}, \\; g = \\begin{bmatrix} 0 \\\\ 9.81 \\end{bmatrix},\\; J = \\begin{bmatrix} 0 & 1 \\end{bmatrix} $$\n",
    "and $\\mu \\in \\mathbb{R}$ is the normal force. The velocity $v \\in \\mathbb{R}^2$ and position $q \\in \\mathbb{R}^2$ are composed of the horizontal and vertical components.\n",
    "\n",
    "We can discretize the dynamics with backward Euler:\n",
    "$$ \\begin{bmatrix} v_{k+1} \\\\ q_{k+1} \\end{bmatrix} = \\begin{bmatrix} v_k \\\\ q_k \\end{bmatrix}\n",
    "+ \\Delta t \\cdot \\begin{bmatrix} \\frac{1}{m} J^T \\mu_{k+1} - g \\\\ v_{k+1} \\end{bmatrix}$$\n",
    "\n",
    "We also have the following contact constraints:\n",
    "$$ \\begin{align}\n",
    "J q_{k+1} &\\geq 0 &&\\text{(don't fall through the ice)} \\\\\n",
    "\\mu_{k+1} &\\geq 0 &&\\text{(normal forces only push, not pull)} \\\\\n",
    "\\mu_{k+1} J q_{k+1} &= 0 &&\\text{(no force at a distance)}\n",
    "\\end{align} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82898d8b",
   "metadata": {},
   "source": [
    "## Part (B): QP formulation for Falling Brick (5 pts)\n",
    "Show that these discrete-time dynamics are equivalent to the following QP by writing down the KKT conditions.\n",
    "\n",
    "$$ \\begin{align}\n",
    "    &\\text{minimize}_{v_{k+1}} && \\frac{1}{2} v_{k+1}^T M v_{k+1} + [M (\\Delta t \\cdot g - v_k)]^Tv_{k+1} \\\\\n",
    "    &\\text{subject to} && -J(q_k + \\Delta t \\cdot v_{k+1}) \\leq 0 \\\\\n",
    "\\end{align} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcacf03",
   "metadata": {},
   "source": [
    "**TASK**: Write down the KKT conditions for the optimization problem above, and show that it's equivalent to the dynamics problem stated previously. Use LaTeX markdown.\n",
    "\n",
    "**PUT ANSWER HERE:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8348c7f",
   "metadata": {},
   "source": [
    "## Part (C): Brick Simulation (5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0852af00",
   "metadata": {},
   "outputs": [],
   "source": [
    "function brick_simulation_qp(q, v; mass = 1.0, Δt = 0.01)\n",
    "    \n",
    "    # TODO: fill in the QP problem data for a simulation step \n",
    "    # fill in Q, q, G, h, but leave A, b the same \n",
    "    # this is because there are no equality constraints in this qp \n",
    "    \n",
    "    qp = (\n",
    "        Q = zeros(2,2), \n",
    "        q = zeros(2),\n",
    "        A = zeros(0,2), # don't edit this\n",
    "        b = zeros(0),   # don't edit this \n",
    "        G = zeros(1,2),\n",
    "        h = zeros(1)\n",
    "    )\n",
    "    \n",
    "    return qp \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8e5cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@testset \"brick qp\" begin \n",
    "    \n",
    "    q = [1,3.0]\n",
    "    v = [2,-3.0]\n",
    "    \n",
    "    qp = brick_simulation_qp(q,v)\n",
    "    \n",
    "    # check all the types to make sure they're right\n",
    "    qp.Q::Matrix{Float64}\n",
    "    qp.q::Vector{Float64}\n",
    "    qp.A::Matrix{Float64}\n",
    "    qp.b::Vector{Float64}\n",
    "    qp.G::Matrix{Float64}\n",
    "    qp.h::Vector{Float64}\n",
    "    \n",
    "    @test size(qp.Q) == (2,2)\n",
    "    @test size(qp.q) == (2,)\n",
    "    @test size(qp.A) == (0,2)\n",
    "    @test size(qp.b) == (0,)\n",
    "    @test size(qp.G) == (1,2)\n",
    "    @test size(qp.h) == (1,)\n",
    "    \n",
    "    @test abs(tr(qp.Q) - 2) < 1e-10\n",
    "    @test norm(qp.q - [-2.0, 3.0981]) < 1e-10 \n",
    "    @test norm(qp.G - [0 -.01]) < 1e-10 \n",
    "    @test abs(qp.h[1] -3) < 1e-10\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42288ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "include(joinpath(@__DIR__, \"animate_brick.jl\"))\n",
    "let \n",
    "    \n",
    "    dt = 0.01 \n",
    "    T = 3.0 \n",
    "    \n",
    "    t_vec = 0:dt:T\n",
    "    N = length(t_vec)\n",
    "    \n",
    "    qs = [zeros(2) for i = 1:N]\n",
    "    vs = [zeros(2) for i = 1:N]\n",
    "    \n",
    "    qs[1] = [0, 1.0]\n",
    "    vs[1] = [1, 4.5]\n",
    "    \n",
    "    # TODO: simulate the brick by forming and solving a qp \n",
    "    # at each timestep. Your QP should solve for vs[k+1], and\n",
    "    # you should use this to update qs[k+1]\n",
    "\n",
    "    \n",
    "    xs = [q[1] for q in qs]\n",
    "    ys = [q[2] for q in qs]\n",
    "    \n",
    "    @show @test abs(maximum(ys)-2)<1e-1\n",
    "    @show @test minimum(ys) > -1e-2\n",
    "    @show @test abs(xs[end] - 3) < 1e-2\n",
    "    \n",
    "    xdot = diff(xs)/dt\n",
    "    @show @test maximum(xdot) < 1.0001\n",
    "    @show @test minimum(xdot) > 0.9999\n",
    "    @show @test ys[110] > 1e-2\n",
    "    @show @test abs(ys[111]) < 1e-2\n",
    "    @show @test abs(ys[112]) < 1e-2\n",
    "    \n",
    "    display(plot(xs, ys, ylabel = \"y (m)\", xlabel = \"x (m)\"))\n",
    "    \n",
    "    animate_brick(qs)\n",
    "    \n",
    "    \n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1db279",
   "metadata": {},
   "source": [
    "# Part D (5 pts): Solve a QP\n",
    "\n",
    "Use your QP solver to solve the following optimization problem:\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{align} \n",
    "\\min_{y\\in\\mathbb{R}^2,a\\in\\mathbb{R},b\\in\\mathbb{R}} \\quad & \\frac{1}{2}y^T \\begin{bmatrix} 1 & .3 \\\\ .3 & 1 \\end{bmatrix} y + a^2 + 2b^2  + \\begin{bmatrix} -2 & 3.4 \\end{bmatrix} y + 2a + 4b \\\\ \n",
    "\\text{st} \\quad & a + b = 1 \\\\ \n",
    "& \\begin{bmatrix}-1 & 2.3 \\end{bmatrix} y + a - 2b =3 \\\\\n",
    "& -0.5 \\leq y \\leq 1 \\\\ \n",
    "& -1 \\leq a \\leq 1 \\\\ \n",
    "& -1 \\leq b \\leq 1\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "You should be able to put this into our standard QP form that we used above, and solve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488cfbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@testset \"part D\" begin\n",
    "\n",
    "    y = randn(2)\n",
    "    a = randn()\n",
    "    b = randn()\n",
    "    \n",
    "    \n",
    "    @test norm(y - [-0.080823; 0.834424]) < 1e-3 \n",
    "    @test abs(a - 1) < 1e-3 \n",
    "    @test abs(b) < 1e-3 \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba575e34",
   "metadata": {},
   "source": [
    "## Part E (5 pts): One sentence short answer\n",
    "\n",
    "1. For our Augmented Lagrangian solver, if our initial guess for $x$ is feasible (meaning it satisfies the constraints), will it stay feasible through each iteration? \n",
    "\n",
    "**put ONE SENTENCE answer here**\n",
    "\n",
    "2. Does the Augmented Lagrangian function for this problem always have continuous first derivatives?\n",
    "\n",
    "**put ONE SENTENCE answer here** \n",
    "\n",
    "3. Is the QP in part D always convex?\n",
    "\n",
    "**put ONE SENTENCE answer here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c7b5a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.7",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
